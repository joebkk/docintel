{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocIntel Demo Notebook\n",
    "\n",
    "Interactive demonstration of the DocIntel multi-agent document intelligence system.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Docker services running: `docker compose up -d`\n",
    "2. Test documents seeded: `docker exec docintel-rag node /app/scripts/seed-test-documents.js`\n",
    "3. Services accessible:\n",
    "   - RAG Backend: http://localhost:3000\n",
    "   - Agent System: http://localhost:8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install requests pandas matplotlib ipywidgets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, JSON\n",
    "\n",
    "# Configuration\n",
    "RAG_BASE_URL = \"http://localhost:3000\"\n",
    "AGENT_BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "print(\"✅ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Health Checks\n",
    "\n",
    "Verify all services are running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_health(service_name, url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"✅ {service_name}: Healthy\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ {service_name}: Unhealthy (status {response.status_code})\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {service_name}: Unreachable - {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"Checking services...\\n\")\n",
    "check_health(\"RAG Backend\", f\"{RAG_BASE_URL}/api/health\")\n",
    "check_health(\"Agent System\", f\"{AGENT_BASE_URL}/health\")\n",
    "check_health(\"Prometheus\", \"http://localhost:9090/-/healthy\")\n",
    "check_health(\"Grafana\", \"http://localhost:3001/api/health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG Backend - Search Modes\n",
    "\n",
    "Test all three search modes: Lexical, Semantic, and Hybrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query, mode=\"hybrid\"):\n",
    "    \"\"\"Search documents using RAG backend.\"\"\"\n",
    "    url = f\"{RAG_BASE_URL}/api/unified-search\"\n",
    "    payload = {\"query\": query, \"mode\": mode}\n",
    "    \n",
    "    response = requests.post(url, json=payload, stream=True)\n",
    "    \n",
    "    sources = []\n",
    "    answer = \"\"\n",
    "    \n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            line_str = line.decode('utf-8')\n",
    "            if line_str.startswith('data: '):\n",
    "                data = json.loads(line_str[6:])\n",
    "                if data.get('type') == 'sources':\n",
    "                    sources = data.get('sources', [])\n",
    "                elif data.get('type') == 'text':\n",
    "                    answer += data.get('content', '')\n",
    "    \n",
    "    return {\"answer\": answer, \"sources\": sources}\n",
    "\n",
    "# Test query\n",
    "query = \"What was the Q3 2024 portfolio performance?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "# Lexical search\n",
    "print(\"\\n=== Lexical Search (BM25) ===\")\n",
    "result = search_documents(query, mode=\"lexical\")\n",
    "print(f\"Sources: {len(result['sources'])}\")\n",
    "display(Markdown(result['answer'][:500] + \"...\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid search (best results)\n",
    "print(\"\\n=== Hybrid Search (Lexical + Semantic) ===\")\n",
    "result = search_documents(query, mode=\"hybrid\")\n",
    "print(f\"\\nSources found: {len(result['sources'])}\")\n",
    "for i, source in enumerate(result['sources'], 1):\n",
    "    print(f\"{i}. {source['fileName']} (score: {source['score']:.2f})\")\n",
    "\n",
    "print(\"\\nAnswer:\")\n",
    "display(Markdown(result['answer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agent System - Basic Query\n",
    "\n",
    "Test the multi-agent orchestration system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_query(query, session_id=None, pattern=\"sequential\"):\n",
    "    \"\"\"Query the agent system.\"\"\"\n",
    "    url = f\"{AGENT_BASE_URL}/query\"\n",
    "    payload = {\n",
    "        \"query\": query,\n",
    "        \"session_id\": session_id,\n",
    "        \"execution_pattern\": pattern\n",
    "    }\n",
    "    \n",
    "    start = time.time()\n",
    "    response = requests.post(url, json=payload)\n",
    "    duration = time.time() - start\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        result['_duration'] = duration\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "# Test query\n",
    "print(\"Testing agent system (may take 10-15 seconds)...\\n\")\n",
    "result = agent_query(\"What were the Q3 2024 results?\", session_id=\"demo-001\")\n",
    "\n",
    "if result:\n",
    "    print(f\"✅ Query completed in {result['_duration']:.2f} seconds\")\n",
    "    print(f\"Workflow ID: {result['workflow_id']}\")\n",
    "    print(f\"Tasks executed: {result['total_tasks']}\")\n",
    "    print(f\"Execution pattern: {result['execution_pattern']}\")\n",
    "    print(\"\\nFinal Answer:\")\n",
    "    display(Markdown(result['result']['final_answer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Session Management\n",
    "\n",
    "Demonstrate conversation history and session persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session\n",
    "def create_session(user_id=None):\n",
    "    url = f\"{AGENT_BASE_URL}/sessions\"\n",
    "    response = requests.post(url, json={\"user_id\": user_id})\n",
    "    return response.json()\n",
    "\n",
    "# Get session messages\n",
    "def get_messages(session_id):\n",
    "    url = f\"{AGENT_BASE_URL}/sessions/{session_id}/messages\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "# Create new session\n",
    "session = create_session(user_id=\"demo-user\")\n",
    "print(f\"Created session: {session['session_id']}\\n\")\n",
    "\n",
    "# Ask multiple questions\n",
    "questions = [\n",
    "    \"What was the Q3 2024 IRR?\",\n",
    "    \"How does that compare to Q2?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"Q: {q}\")\n",
    "    # Note: Will hit Gemini quota - wait 60s between queries in production\n",
    "    time.sleep(60)  # Wait for Gemini quota\n",
    "    result = agent_query(q, session_id=session['session_id'])\n",
    "    if result:\n",
    "        print(f\"A: {result['result']['final_answer'][:200]}...\\n\")\n",
    "\n",
    "# Get conversation history\n",
    "messages = get_messages(session['session_id'])\n",
    "print(f\"\\nConversation history ({len(messages['messages'])} messages):\")\n",
    "for msg in messages['messages']:\n",
    "    print(f\"[{msg['role'].upper()}]: {msg['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Execution Patterns Comparison\n",
    "\n",
    "Compare Sequential vs Parallel execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_query = \"Compare performance metrics across all portfolio companies\"\n",
    "\n",
    "print(\"Testing execution patterns...\\n\")\n",
    "\n",
    "# Sequential\n",
    "print(\"1. Sequential execution:\")\n",
    "result_seq = agent_query(complex_query, pattern=\"sequential\")\n",
    "if result_seq:\n",
    "    print(f\"   Duration: {result_seq['duration_seconds']:.2f}s\")\n",
    "    print(f\"   Tasks: {result_seq['total_tasks']}\")\n",
    "\n",
    "time.sleep(60)  # Wait for Gemini quota\n",
    "\n",
    "# Parallel\n",
    "print(\"\\n2. Parallel execution:\")\n",
    "result_par = agent_query(complex_query, pattern=\"parallel\")\n",
    "if result_par:\n",
    "    print(f\"   Duration: {result_par['duration_seconds']:.2f}s\")\n",
    "    print(f\"   Tasks: {result_par['total_tasks']}\")\n",
    "    \n",
    "    speedup = result_seq['duration_seconds'] / result_par['duration_seconds']\n",
    "    print(f\"\\n   Speedup: {speedup:.2f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Memory Bank\n",
    "\n",
    "Store and retrieve long-term memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store memory\n",
    "def store_memory(content, memory_type=\"fact\", importance=0.8, tags=None):\n",
    "    url = f\"{AGENT_BASE_URL}/memory\"\n",
    "    payload = {\n",
    "        \"content\": content,\n",
    "        \"memory_type\": memory_type,\n",
    "        \"user_id\": \"demo-user\",\n",
    "        \"importance\": importance,\n",
    "        \"tags\": tags or []\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Retrieve memories\n",
    "def get_memories(user_id=\"demo-user\", min_importance=0.5):\n",
    "    url = f\"{AGENT_BASE_URL}/memory\"\n",
    "    params = {\"user_id\": user_id, \"min_importance\": min_importance}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Store some facts\n",
    "memories_to_store = [\n",
    "    {\"content\": \"Q3 2024 IRR was 15%\", \"type\": \"fact\", \"importance\": 0.9, \"tags\": [\"Q3\", \"IRR\"]},\n",
    "    {\"content\": \"User prefers detailed financial analysis\", \"type\": \"preference\", \"importance\": 0.8, \"tags\": [\"preferences\"]},\n",
    "    {\"content\": \"Portfolio shows strong fintech sector performance\", \"type\": \"insight\", \"importance\": 0.7, \"tags\": [\"trends\"]}\n",
    "]\n",
    "\n",
    "print(\"Storing memories...\\n\")\n",
    "for mem in memories_to_store:\n",
    "    result = store_memory(mem[\"content\"], mem[\"type\"], mem[\"importance\"], mem[\"tags\"])\n",
    "    print(f\"✅ Stored: {mem['content'][:50]}...\")\n",
    "\n",
    "# Retrieve\n",
    "print(\"\\nRetrieving memories (importance >= 0.7):\\n\")\n",
    "memories = get_memories(min_importance=0.7)\n",
    "for mem in memories['memories']:\n",
    "    print(f\"- [{mem['memory_type'].upper()}] {mem['content']}\")\n",
    "    print(f\"  Importance: {mem['importance']}, Tags: {mem['tags']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Checkpointing (Human-in-Loop)\n",
    "\n",
    "Save and restore session state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint\n",
    "def create_checkpoint(session_id):\n",
    "    url = f\"{AGENT_BASE_URL}/sessions/{session_id}/checkpoint\"\n",
    "    response = requests.post(url)\n",
    "    return response.json()\n",
    "\n",
    "# Restore checkpoint\n",
    "def restore_checkpoint(checkpoint_id):\n",
    "    url = f\"{AGENT_BASE_URL}/checkpoints/{checkpoint_id}/restore\"\n",
    "    response = requests.post(url)\n",
    "    return response.json()\n",
    "\n",
    "# Create a session with some activity\n",
    "session = create_session(user_id=\"checkpoint-demo\")\n",
    "print(f\"Created session: {session['session_id']}\\n\")\n",
    "\n",
    "# Ask a question\n",
    "time.sleep(60)  # Gemini quota\n",
    "agent_query(\"What was Q3 performance?\", session_id=session['session_id'])\n",
    "\n",
    "# Create checkpoint\n",
    "checkpoint = create_checkpoint(session['session_id'])\n",
    "print(f\"\\n✅ Checkpoint created: {checkpoint['checkpoint_id']}\")\n",
    "print(\"   You can now restore this state later to continue the conversation.\")\n",
    "\n",
    "# Later: Restore\n",
    "# restored = restore_checkpoint(checkpoint['checkpoint_id'])\n",
    "# print(f\"Restored session: {restored['session_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Observability - Metrics\n",
    "\n",
    "Query Prometheus for system metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_prometheus(query):\n",
    "    url = \"http://localhost:9090/api/v1/query\"\n",
    "    response = requests.get(url, params={\"query\": query})\n",
    "    return response.json()\n",
    "\n",
    "# Get metrics\n",
    "metrics = [\n",
    "    (\"Active Sessions\", \"agent_active_sessions\"),\n",
    "    (\"Total Workflows\", \"agent_workflow_total\"),\n",
    "    (\"LLM Tokens Used\", \"agent_llm_tokens_total\")\n",
    "]\n",
    "\n",
    "print(\"System Metrics:\\n\")\n",
    "for label, query in metrics:\n",
    "    result = query_prometheus(query)\n",
    "    if result['status'] == 'success' and result['data']['result']:\n",
    "        value = result['data']['result'][0]['value'][1]\n",
    "        print(f\"{label}: {value}\")\n",
    "    else:\n",
    "        print(f\"{label}: No data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✅ **Health Checks** - Verify all services\n",
    "2. ✅ **Search Modes** - Lexical, Semantic, Hybrid\n",
    "3. ✅ **Agent Queries** - Multi-agent orchestration\n",
    "4. ✅ **Sessions** - Conversation history\n",
    "5. ✅ **Execution Patterns** - Sequential vs Parallel\n",
    "6. ✅ **Memory Bank** - Long-term storage\n",
    "7. ✅ **Checkpointing** - Save/restore state\n",
    "8. ✅ **Observability** - Metrics and monitoring\n",
    "\n",
    "**Next Steps**:\n",
    "- See `evaluation.ipynb` for Kaggle competition criteria demonstrations\n",
    "- Check Grafana dashboards: http://localhost:3001\n",
    "- View traces in Jaeger: http://localhost:16686"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
